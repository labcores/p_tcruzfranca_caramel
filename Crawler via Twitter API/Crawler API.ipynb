{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawler API\n",
    "\n",
    "Crawler que consome a API do Twitter para coletar tweets presentes na timeline de um usuário.\n",
    "\n",
    "Este notebook é um guia! Você vai precisar rodar localmente o código, mas não pule essa etapa, pois é muito importante entender como funciona a ferramenta e como manipular os dados que você coletar.\n",
    "\n",
    "# Introdução\n",
    "\n",
    "Para dar um pouco de contexto, vamos ver o motivo desse crawler ter sido criado. Ele foi modelado para coletar dados que \n",
    "identificassem como a fila da timeline do twitter se forma, por isso ele se concentrou em observar o próprio usuário logado em vez de diversos tweets espalhados pela rede.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando o Ambiente\n",
    "\n",
    "O Twitter se tornou mais restrito quanto a quem pode ter uma chave de acesso à sua API. É necessário pedir uma conta de desenvolvedor na página [apps.twitter.com] e justificar o seu uso.\n",
    "\n",
    "Entre na sua conta do Twitter e em seguida crie uma aplicação na página [https://developer.twitter.com/en/apps]. O nome e a descrição não importam muito, faça como quiser. Para preencher o campo 'website URL' use qualquer link, até um que não seja registrado. \n",
    "\n",
    "Infelizmente a burocracia não acabou e você precisa descrever qual é seu objetivo fazendo esse app, a boa notícia é o mínimo ser de apenas 100 caracteres.\n",
    "\n",
    "Ao final do processo, você terá à disposição algumas credenciais que iremos usar adiante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conectando à API do twitter\n",
    "\n",
    "Para se conectar a API, você vai escrever as credenciais geradas pelo app num arquivo chamado \"credentials.txt\".\n",
    "\n",
    "## Exemplo de credenciais\n",
    "\n",
    "#### O arquivo precisa estar no formato abaixo com seus dados\n",
    "\n",
    "Consumer_key = uQl2J9OpHkqXcBKdrNjU09UB0\n",
    "\n",
    "Consumer_secret = FdGsRUWESM3wrQVF6nDrOgsgi99CpwOvylA3yBt1m6EeJn1btg\n",
    "\n",
    "Acess_token = 772557411177623882-GtuCaR7jApm6BGUVsnjyGXQIiHfKjiy\n",
    "\n",
    "Acess_token_secret = d5n1VTrHIULSHSTF9VueoBOUZIlzsN7nFWkZkn0Ap1dPE2\n",
    "\n",
    "\n",
    "### Atenção!\n",
    "\n",
    "As credenciais acima são apenas ilustrativas. Quando você gerar suas credenciais, JAMAIS compartilhe elas em lugar algum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bibliotecas\n",
    "\n",
    "A biblioteca OAuth2 será usada para autenticar nossa conexão à API do twitter, o pymongo será usado para nos conectar ao banco mongo responsável por salvar nossos dados.\n",
    "\n",
    "\n",
    "\n",
    "# JSON\n",
    "\n",
    "Todos os tweets coletados serão salvos no formato JSON. Caso encontre alguma dificuldade em manipular ou entender o formato, confira esse artigo: https://pythonhelp.wordpress.com/2013/03/21/acessando-conteudo-via-apis-web-baseadas-em-json/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n__author__ = \"Tiago Cruz de França\"\\n__copyright__ = \"Copyright 2018, UFRRJ\"\\n__credits__ = [\"Tiago França\"]\\n__license__ = \"GPL\"\\n__version__ = \"0.0.1\"\\n__maintainer__ = \"Tiago França, Edu Mangabeira\"\\n__email__ = \"tcruz.franca@gmail.com\"\\n__status__ = \"Test\"\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import oauth2 as oauth\n",
    "import json\n",
    "import time\n",
    "import codecs\n",
    "import sys\n",
    "import datetime\n",
    "import pymongo\n",
    "\n",
    "'''\n",
    "__author__ = \"Tiago Cruz de França\"\n",
    "__copyright__ = \"Copyright 2018, UFRRJ\"\n",
    "__credits__ = [\"Tiago França\"]\n",
    "__license__ = \"GPL\"\n",
    "__version__ = \"0.0.1\"\n",
    "__maintainer__ = \"Tiago França, Edu Mangabeira\"\n",
    "__email__ = \"tcruz.franca@gmail.com\"\n",
    "__status__ = \"Test\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acessando o mongoDB\n",
    "\n",
    "\n",
    "Agora vai uma explicação rápida sobre o banco mongo, você pode pular essa parte por enquanto, pois só vai poder testar depois que todo o código for executado e os dados obtidos.\n",
    "\n",
    "1) Para iniciar no seu terminal, basta digitar 'mongo'.\n",
    "\n",
    "2) Primeiro é preciso ver quais bancos estão sendo usados na sua máquina, o comando a ser usado é 'show dbs'.\n",
    "\n",
    "3) Para usar um banco: 'use {insira aqui um banco, sem chaves}'\n",
    "\n",
    "4) Agora temos que selecionar uma coleção do nosso banco, para ver as coleções: 'show collections'.\n",
    "\n",
    "5) Existem diferentes formas de acessar os dados, vou citar algumas.\n",
    "\n",
    "5.1) 'db.{sua collection}.find()' mostra alguns tweets, é útil para verificar rapidamente erros em parâmetros. Também é possível filtrar a procura, para saber com mais detalhes veja em: https://docs.mongodb.com/manual/reference/method/db.collection.find/\n",
    "\n",
    "5.2) 'db.{sua collection}.findOne()' mostra apenas um tweet e também pode filtrar a busca(recomendado nesse caso).\n",
    "\n",
    "Se você deseja apenas um arquivo com a base de dados, volte para o seu terminal(crtl+C interrompe o processo mongo) e digite o seguinte comando:\n",
    "\n",
    "##### Para obter .json\n",
    "mongoexport --db {seu_banco} --collection {sua_coleção} --out {diretorio/nome_do_seu_arquivo}.json\n",
    "\n",
    "##### Para obter .csv\n",
    "mongoexport --db {seu_banco} --collection {sua_coleção} --type=csv --out {diretorio/nome_do_seu_arquivo}.csv\n",
    "\n",
    "Existem opções mais específicas não citadas aqui, como obter apenas alguns campos da tabela. Aqui está a documentação do MongoDB, caso queria usar mais alguma função não apresentada aqui. https://docs.mongodb.com/manual/tutorial/getting-started/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo uma coleta\n",
    "\n",
    "A partir daqui pode ficar um pouco complicado entender todo o código. O que é importante mesmo de forma mais direta se encontra a partir da função \" *Salvartweets(data, collection, collection2, log, screen_name)* \". Caso encontre alguma dificuldade em entender o que a ferramenta faz, pule direto para lá.\n",
    "\n",
    "\n",
    "Não se preocupe muito agora em entender a classe abaixo em detalhes, ela apenas será criada para nos ajudar a salvar um tweet com uma boa formatação no nosso banco de dados. Ela obtém um padrão de identificação entre cada coleta.\n",
    "\n",
    "Ao longo do código pode ser que você esbarre em uma função ou outra que não aparente ter uma utilidade clara, por isso os pontos principais estarão bem destacados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SnapshotIdSingleton(object):\n",
    "\n",
    "    snapshot = None\n",
    "    aux = 0\n",
    "    def __init__(self):\n",
    "        if (self.aux == 0):\n",
    "            self.__done__()\n",
    "            self.__del__()\n",
    "\n",
    "    def __del__(self):\n",
    "        print(\"objeto destruido\") \n",
    "   \n",
    "    def __done__(self):\n",
    "        print (\"Por favor, use o metodo instance para criar uma instancia desta classe, ela e singleton\")\n",
    "\n",
    "    def getLastSnapShotIdFromMongo(self, collection):\n",
    "        register = collection.find({},{\"_id\":0,\"snapshot_id\":1}).sort(\"snapshot_id\",pymongo.DESCENDING).limit(1)\n",
    "        register = register.next()\n",
    "        return register[\"snapshot_id\"]\n",
    "\n",
    "    \n",
    "    @classmethod \n",
    "    def instance(cls):\n",
    "        if (cls.snapshot == None):\n",
    "            cls.aux = 1\n",
    "            cls.snapshot = SnapshotIdSingleton()\n",
    "            cls.aux = 0\n",
    "\n",
    "        return cls.snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez não se preocupe, o registro de erros é apenas uma função para facilitar o desenvolvimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logError(log, msg):\n",
    "    log.write(msg+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É uma função que vai ser usada ao longo do código para auxiliar as outras, seu propósito ficará mais claro adiante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def salvarArquivo(data, destino, log):\n",
    "    #for registro in data:\n",
    "    #print \"escreveu no arquivo\"\n",
    "    data = json.loads(data)\n",
    "    #print data\n",
    "    order = 1\n",
    "    for registro in data:\n",
    "        try:            \n",
    "            #print \"vaiEscreverNoArquivo\"\n",
    "            #print registro\n",
    "            destino.write(\"{\\\"order\\\":\"+str(order)+\",\\\"tweet\\\":\"+json.dumps(registro)+\"}\\n\")\n",
    "            #print \"Escreveu\"\n",
    "            #destino.flush()\n",
    "            #print \"flush\"\n",
    "            order += 1\n",
    "        except:\n",
    "            msg = \"Ao Salvar o Arquivo\"\n",
    "            logError(log, msg)\n",
    "            print (\"Unexpected error:\" + str(sys.exc_info()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salva somente o texto e id de um tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customTweet(data, destino, ids):\n",
    "    data = json.loads(data)\n",
    "    cont = 0\n",
    "    for row in data:\n",
    "        destino.write(str(cont)+\": \"+json.dumps(row[\"text\"])+'\\n')\n",
    "        ids.write(str(cont)+\": \"+json.dumps(str(row[\"id\"]))+\"\\n\")\n",
    "        cont+=1\n",
    "        #timeStamp.write(json.dumps(row[\"created_at\"],'\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembra da classe que criamos acima? Agora nós iremos usar uma função para instanciá-la e podermos preencher esse campo(identificação da coleta) no nosso banco ao chamar essa função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obterLastSnapshotId(collection):\n",
    "    resultado = SnapshotIdSingleton.instance()\n",
    "    try:\n",
    "        resultado = resultado.getLastSnapShotIdFromMongo(collection)\n",
    "    except:\n",
    "        resultado = 0\n",
    "\n",
    "    resultado += 1\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando tweets\n",
    "\n",
    "Aqui nós salvamos os tweets que coletarmos mais adiante no nosso banco de dados, com os seguintes campos:\n",
    "* snapShotID: é a identificação da coleta realizada, então é comum ver mais de um tweet com esse registro\n",
    "* snapshot_timestamp ou time_stamp: marca a hora em que a coleta foi realizada, útil para relacionar com a hora real de publicação dos tweets.\n",
    "* bot_screen_name: obtém o @ do usuário logado/autenticado(um bot no caso).\n",
    "* id_tweet: identificação do tweet.\n",
    "* publisher_screen_name: pega o @ do perfil de quem publicou o tweet.\n",
    "* impression_order: marca o número da coleta à qual o tweet pertence.\n",
    "* retweet_count: quantidade de retweets numa publicação.\n",
    "* favorite_count: quantidade de curtidas numa publicação.\n",
    "* created_at_tweet: data de criação de um tweet, pode ser interessante cruzar esse dado com o timestamp ou impression order.\n",
    "* text: texto de um tweet.\n",
    "\n",
    "Essa função é uma adaptação de *salvarArquivo* para o projeto de modelagem da timeline, esses campos foram escolhidos assim porque foram pensados no ponto de vista de um *usuário* e o que a API do twitter mostra sobre a timeline dele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def salvarTweets(data, collection, destino, log, screen_name):\n",
    "def salvarTweets(data, collection, collection2, log, screen_name):\n",
    "\n",
    "    timestamp_snapshot = datetime.datetime.utcnow().strftime(\"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "    #destino.write(\"\\n\"+timestamp_snapshot+\"\\t\"+screen_name+\"\\n\")\n",
    "   \n",
    "    data = json.loads(data)\n",
    "    order = 1\n",
    "    snapShotId = obterLastSnapshotId(collection)\n",
    "\n",
    "    for registro in data:\n",
    "        try:\n",
    "            print (\"111111111111111111111\")\n",
    "            #destino.write(\"{\\\"order\\\":\"+str(order)+\",\\\"tweet\\\":\"+json.dumps(registro)+\"}\\n\")\n",
    "            completJSON = {'snapShotId':snapShotId, 'time_stamp':timestamp_snapshot, 'bot_screen_name':screen_name, 'impression_order':order,'tweet':json.dumps(registro)}\n",
    "\n",
    "            print (\"22222222222222222222\")\n",
    "\n",
    "            adjustedJSON = {'id_tweet':registro[\"id\"],'bot_screen_name': screen_name,'publisher_screen_name':registro[\"user\"][\"screen_name\"],'snapshot_id': snapShotId,'snapshot_timestamp':timestamp_snapshot,'impression_order':order,'retweet_count':registro[\"retweet_count\"],'favorite_count':registro[\"favorite_count\"],'created_at_tweet':registro[\"created_at\"],'text':registro[\"text\"]}\n",
    "\n",
    "            #if (screen_name != \"\"):         \n",
    "            #    adjustedJSON[\"bot_screen_name\"] = screen_name\n",
    "\n",
    "            collection.insert_one(adjustedJSON)\n",
    "            collection2.insert_one(completJSON)\n",
    "            print (\"3333333333333333333333\")\n",
    "\n",
    "            order += 1\n",
    "\n",
    "        except:\n",
    "            msg = \"Ao Salvar o Arquivo\"\n",
    "            logError(log, msg)\n",
    "            print (\"Unexpected error:\" + str(sys.exc_info()[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função abaixo é similar à anterior, mas com um adendo, agora estamos interessados em salvar também os dados da timeline de um usuário especificado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def salvarPublisherTweets(data, collection, destino, log):\n",
    "def salvarPublisherTweets(data, collection, collection2, log):\n",
    "\n",
    "    data = json.loads(data)\n",
    "\n",
    "    for registro in data:\n",
    "        try:\n",
    "\n",
    "            #destino.write(\"{\\\"tweet\\\":\"+json.dumps(registro)+\"}\\n\")\n",
    "            adjustedJSON = {'id_tweet':registro[\"id\"],'publisher_screen_name':registro[\"user\"][\"screen_name\"],'retweet_count':registro[\"retweet_count\"],'favorite_count':registro[\"favorite_count\"],'created_at_tweet':registro[\"created_at\"]}\n",
    "\n",
    "            collection.insert_one(adjustedJSON)\n",
    "            collection2.insert_one(registro)\n",
    "\n",
    "        except:\n",
    "            msg = \"Ao Salvar o Arquivo\"\n",
    "            logError(log, msg)\n",
    "            print (\"Unexpected error:\" + str(sys.exc_info()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptação do método customTweet para o projeto de modelagem da timeline.\n",
    "A mudança é que a cada solicitação para salvar no arquivo eu incluo uma linha em branco, a hora UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customTweetAdapter(data, destino, ids,screen_name=\"\"):\n",
    "\n",
    "    destino.write(\"\\n\"+datetime.datetime.utcnow().strftime(\"%a %b %d %H:%M:%S +0000 %Y\")+\"\\t\"+screen_name+\"\\n\")\n",
    "    ids.write(\"\\n\"+datetime.datetime.utcnow().strftime(\"%a %b %d %H:%M:%S +0000 %Y\")+\"\\t\"+screen_name+\"\\n\")\n",
    "    customTweet(data, destino, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pegando dados de um usuário especificado\n",
    "\n",
    "\n",
    "Além de coletar a user_home(a do usuário autenticado)queremos os dados de uma timeline especificada pelo usuário, acima já fizemos uma função para salvar no banco, agora falta construir essa de coleta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pegarTweetsDeUmUsuario(user, tweetTexto,destino, ids,maxTweets=1):\n",
    "\n",
    "    if maxTweets > 200:\n",
    "        maxTweets = 200\n",
    "        print (\"A quantidade maxima de tweets é 200\")\n",
    "    maxId = 0\n",
    "\n",
    "    cont = 0\n",
    "    while True:\n",
    "        URL = \"https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=\"+user+\"&count=\"+str(maxTweets)\n",
    "        if (maxId > 0):\n",
    "            URL +=\"&max_id=\" + str(maxId)\n",
    "        response,data = client.request(URL,\"GET\")\n",
    "\n",
    "        print (\"a\",maxId)\n",
    "        maxId = (json.loads(data)[-1]['id'] - 1)\n",
    "        print (\"b\",maxId)\n",
    "\n",
    "        if (cont >= 10):\n",
    "            break;\n",
    "        cont += 1\n",
    "\n",
    "        customTweet(data, tweetTexto, ids)\n",
    "\n",
    "        salvarArquivo(data, destino,log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função abaixo é uma adaptação da função pegarTweetsDeUmUsuario. A diferença é que se deseja pegar uma quantidade  (max de 200) de mensagens de uma timeline dado um intervalo de tempo. Esses dados são sempre os mais\n",
    "recentes na timeline ainda que sejam repetidos a cada coleta. Por exemplo, se eu pego 5 tweets mais recentes e rodo novamente em 1 minuto e apenas uma nova mensagem chegou, pegarei os 5 mais recentes (o novo\n",
    "e os outros 4 que já tinha coletado na rodada anterior).\n",
    "\n",
    "Parâmetros:\n",
    "* user: identifica perfil do twitter que está sendo 'monitorado'\n",
    "* tweetTexto: é uma referência para um arquivo. Nele será apenas o texto do twitter.\n",
    "* destino: arquivo para salvar os tweets coletados (todo o json).\n",
    "* ids: é o arquivo para salvar os ids dos tweets.        \n",
    "* collection: é a coleção para salvar os dados no mongo.\n",
    "* intervalColeta: intervalo de coleta das mensagens em segundos.\n",
    "* maxTweets: define a quantidade máxima de mensagens solicitadas a cada requisição. Pela API o máximo são de 200 mensagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def pegarTweetsDeUmUsuarioQtdeIntervalo(user, tweetTexto,destino, ids, collection, intervalColeta=60, maxTweets=200):\n",
    "def pegarTweetsDeUmUsuarioQtdeIntervalo(user, collection, collection2, intervalColeta=60, maxTweets=200):\n",
    "    \n",
    "    if maxTweets > 200:\n",
    "        maxTweets = 200\n",
    "        print (\"A quantidade maxima de tweets é 200\")\n",
    "    sinceId = 0\n",
    "\n",
    "    cont = 0\n",
    "    while True:\n",
    "        URL = \"https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=\"+user+\"&count=\"+str(maxTweets)\n",
    "        if (sinceId > 0):\n",
    "            URL +=\"&since_id=\" + str(sinceId)\n",
    "\n",
    "        try:\n",
    "\n",
    "            response,data = client.request(URL,\"GET\")\n",
    "\n",
    "            sinceId = (json.loads(data)[0]['id']) #sempre coletar os posteriores a um certo id\n",
    "\n",
    "            '''\n",
    "            #apenas consulta 10x a API obtendo 10x a quantidade de tweets passada (se disponivel essa qtde).\n",
    "            if (cont >= 10):\n",
    "                break;\n",
    "            cont += 1\n",
    "            '''\n",
    "            #customTweetAdapter(data, tweetTexto, ids)\n",
    "            #salvarPublisherTweets(data, collection, destino,log)\n",
    "            salvarPublisherTweets(data, collection, collection2, log)\n",
    "\n",
    "        except:\n",
    "            print (\"quantidade maxima de tweets disponivel atingida. Ou seja, se vc pediu 10 e so tem 9, da erro.\")\n",
    "        finally:\n",
    "            print (\"finally\")\n",
    "            #time.sleep(intervalColeta) #dorme a cada iteracao\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegando a timeline de um usuário autenticado\n",
    "\n",
    "\n",
    "A próxima função pega da home_timeline (linha do tempo do usuário com publicações dele e de quem ele segue).Pega a quantidade especificada em maxTweets (maximo de 200) dos tweets mais recentes na timeline.\n",
    "\n",
    "No trabalho original nós queríamos pegar repetições (tweets que ele já viu, sem controlar se ele pega tweets que já foram recuperados antes - que seria feito com since_id, no caso). Na nossa pergunta seria sobre a timeline \"como pegar apenas as mensagens mais recentes (20 últimas publicadas)?\"... resolvido a explicação acima.\n",
    "\n",
    "\n",
    "Parâmetros:\n",
    "* tweetTexto - arquivo onde serão salvos os textos de cada tweet.\n",
    "* destino - arquivo que salva tweets no formato JSON.\n",
    "* ids - arquivo que salva o id dos tweets, esse arquivo é importante pois é possível obter o id de tweets de 30 dias atrás e é possível recuperar tweets antigos pelo id. \n",
    "* maxTweets - é usado para limitar o número de tweets a serem recuperados o valor padrão é 20 e o máximo é 200, mas atenção - max_id e maxTweets são parâmetros distintos.\n",
    "\n",
    "É ainda possível usar outros parâmetros, confira a referência: https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-home_timeline\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pegarTimelineAuthUser(tweetTexto,destino,ids,maxTweets=100):\n",
    "\n",
    "    '''\n",
    "        Information:\n",
    "            Response formats: JSON\n",
    "            Require authentication\n",
    "            Rate limits: 15 to each 15 minutes\n",
    "    '''\n",
    "\n",
    "    if maxTweets > 200:\n",
    "        maxTweets = 200\n",
    "        print (\"A quantidade maxima de tweets é 200\")\n",
    "    maxId = 0\n",
    "\n",
    "    cont = 0\n",
    "    while True:\n",
    "        URL = \"https://api.twitter.com/1.1/statuses/home_timeline.json?count=\"+str(maxTweets)#+\"&include_entities=false\"#to exclude entites from json response\n",
    "        if (maxId > 0):\n",
    "            URL +=\"&max_id=\" + str(maxId)\n",
    "        response,data = client.request(URL,\"GET\")\n",
    "\n",
    "        maxId = (json.loads(data)[-1]['id'] - 1)\n",
    "\n",
    "        '''incluir testes do tamanho da janela'''\n",
    "\n",
    "        if cont > 0:\n",
    "            break       \n",
    "\n",
    "        cont += 1\n",
    "\n",
    "        customTweet(data, tweetTexto, ids)\n",
    "\n",
    "        salvarArquivo(data, destino,log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma adaptação da função anterior, nós iremos chamá-la na main para começar a coleta dos tweets e inserção no banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def pegarTimelineAuthUserProjetoTimeline(tweetTexto,destino,ids,collection, screen_name,intervalColeta=60,maxTweets=200):\n",
    "def pegarTimelineAuthUserProjetoTimeline(collection, collection2, screen_name,intervalColeta=60,maxTweets=200):\n",
    "\n",
    "    if maxTweets > 200:\n",
    "        maxTweets = 200\n",
    "        print \"A quantidade maxima de tweets é 200\"\n",
    "    #maxId = 0\n",
    "\n",
    "    #cont = 0\n",
    "    while True:\n",
    "        URL = \"https://api.twitter.com/1.1/statuses/home_timeline.json?count=\"+str(maxTweets)#+\"&include_entities=false\"#to exclude entites from json response\n",
    "        #if (maxId > 0):\n",
    "        #    URL +=\"&max_id=\" + str(sinceId)\n",
    "\n",
    "        try: #nao precisa, mas deixei porque estava dando erro quando estava usando maxId\n",
    "            response,data = client.request(URL,\"GET\")\n",
    "            #maxId = (json.loads(data)[-1]['id']-1)#uma lista de tweets (padrao e 200 no param maxTweets) sao obtidos. Aqui pego o id do ultimo tweet da lista. Entao coleto os mais antigos, antes dele na proxima iteracao.\n",
    "\n",
    "            '''incluir testes do tamanho da janela\n",
    "\n",
    "            if cont > 0:\n",
    "                break       \n",
    "            \n",
    "            cont += 1\n",
    "            '''\n",
    "            #customTweetAdapter(data, tweetTexto, ids, screen_name)\n",
    "            #salvarTweets(data, collection, destino, log, screen_name)\n",
    "            salvarTweets(data, collection, collection2, log, screen_name)\n",
    "            #contExc = 0\n",
    "        except:\n",
    "           print \"exception\"\n",
    "           #contExc += 1\n",
    "            \n",
    "        finally:\n",
    "            print \"finally\"           \n",
    "            time.sleep(intervalColeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A que vamos ver agora é complementar à próxima, basicamente ela vai fazer uma requisição para pegar tweets antigos baseados no id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pegarTweets(ids, destino, log):\n",
    "\n",
    "    listaIds = \"\"\n",
    "    URL = \"https://api.twitter.com/1.1/statuses/lookup.json?id=\"\n",
    "    for j in ids:\n",
    "        listaIds += str(j)+\",\"\n",
    "    \n",
    "    listaIds = listaIds[:-1]#remover ultima virgula\n",
    "    URL += listaIds\n",
    "    #print \"vaiEnviarReqisição\"\n",
    "    response,data = client.request(URL,\"GET\")\n",
    "\n",
    "    #print \"enviouRequisiçãoVaiSalvar\"\n",
    "    salvarArquivo(data, destino,log)\n",
    "    #print \"Salvou\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função abaixo está comentada na main, mas se você quiser usá-la, o que ela faz é coletar os tweets antigos salvos por ID naquele arquivo anterior da função *pegarTimelineAuthUser*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coletarTweetsAntigos(arqIDs, destino, log):\n",
    "    ids = []\n",
    "\n",
    "    #arqIDs = [\"577982721596723200\"]\n",
    "\n",
    "    for i in arqIDs:\n",
    "        #i = i.replace(\"\\n\",\"\")\n",
    "        #i = i.replace(\"\\r\",\"\")\n",
    "        i = re.sub(\"[^0-9]\",\"\",i)\n",
    "\n",
    "\n",
    "        ids.append(i)\n",
    "        \n",
    "            #URL = \"https://api.twitter.com/1.1/statuses/user_timeline.json?screen_name=tcruzfranca&count=1\"\n",
    "        if len(ids) == 100:\n",
    "            try:\n",
    "                print \"pegaTweets\"\n",
    "                pegarTweets(ids,destino,log)\n",
    "                print \"depoisPegarTweets\"\n",
    "                time.sleep(5)                        \n",
    "            except:\n",
    "                msg = \"Erro ao coletar.\"                \n",
    "                #logErro(log,msg)\n",
    "                print \"Unexpected error:\"+ str(sys.exc_info()[0])\n",
    "                print \"dormiu\"\n",
    "                time.sleep(60*15)\n",
    "                pegarTweets(ids,destino,log)\n",
    "            finally:\n",
    "                ids = []\n",
    "\n",
    "    else:\n",
    "        pegarTweets(ids,destino, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As duas próximas funções serão usadas apenas para auxiliar a main().\n",
    "\n",
    "\n",
    "É necessário obter o screen_name(@ do seu usuário) para salvar os dados no banco mongo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getScreenNameAuthUser():\n",
    "\n",
    "    URL = \"https://api.twitter.com/1.1/account/settings.json\"\n",
    "    response, data = client.request(URL,\"GET\")\n",
    "\n",
    "    screen_name = json.loads(data)\n",
    "    screen_name = screen_name[\"screen_name\"]\n",
    "    return screen_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora nós vamos validar as suas credenciais, aquelas que foram fornecidas anteriormente ao arquivo \"credentials.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCredentials():\n",
    "    \n",
    "    arq = open(\"credentials.txt\")\n",
    "    \n",
    "    credentials = {}\n",
    "\n",
    "    for i in arq:\n",
    "        i = i.replace(\"\\n\",\"\")\n",
    "        i = i.replace(\" \",\"\")\n",
    "        aux = i.split(\"=\")\n",
    "        key = aux[0]\n",
    "        value = aux[1]\n",
    "        \n",
    "        credentials.update({key:value})\n",
    "\n",
    "    return credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dependências da função main: oauth2 e codecs\n",
    "\n",
    "# Função main\n",
    "\n",
    "###### pegarTimelineAuthUserProjetoTimeline: pega conteúdo da timeline do usuário proprietário das credenciais.\n",
    "###### pegarTweetsDeUmUsuarioQtdeIntervalo: pega conteúdo da timeline de um usuário específico(o que ele publicou).\n",
    "  \n",
    "  \n",
    "  Será perguntado a você(no terminal da sua máquina) qual o intervalo entre as coletas(em segundos!!!) e a quantidade de tweets por requisição independentemente de qual função for escolhida. O padrão é de 30 tweets a cada 1500 segundos.\n",
    "  \n",
    "  E pronto! Agora basta deixar o programa rodando, cuidado apenas com quedas de energia ou falhas em conexão de rede. É de extrema importância monitorar as coletas para não perder dados importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getCredentials' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b1ac43ceb3e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcredenciais\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetCredentials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mConsumer_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcredenciais\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Consumer_key'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'getCredentials' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    credenciais = getCredentials()\n",
    "\n",
    "    Consumer_key = credenciais['Consumer_key']\n",
    "    Consumer_secret = credenciais['Consumer_secret']\n",
    "    Access_token = credenciais['Access_token']\n",
    "    Access_token_secret = credenciais['Access_token_secret']\n",
    "\n",
    "    consumer = oauth.Consumer(key=Consumer_key, secret=Consumer_secret)\n",
    "    access_token = oauth.Token(key=Access_token, secret=Access_token_secret)\n",
    "    client = oauth.Client(consumer, access_token)\n",
    "\n",
    "\n",
    "    arquivo = raw_input(\"Forneca o nome do banco onde serao salvos os dados da coleta:\")\n",
    "    #print (\"Esse mesmo nome tambem sera usado para salvar todos os dados em um arquivo.\")\n",
    "\n",
    "    #substitua os nomes dos arquivos\n",
    "    #salvarTweet = arquivo+\".txt\"\n",
    "    #salvarApenasIdsTweets = arquivo+\"_ids.txt\"\n",
    "    #salvarApenasTextoTweets = arquivo+\"_texto.txt\"\n",
    "    salvarLogErros = arquivo+\"_log.txt\"\n",
    "\n",
    "    #destino = codecs.open(salvarTweet, \"a\", \"utf-8\")\n",
    "    #tweets_ids = codecs.open(salvarApenasIdsTweets, \"a\", \"utf-8\")\n",
    "    #tweets_texto= codecs.open(salvarApenasTextoTweets, \"a\", \"utf-8\")\n",
    "    log = open(salvarLogErros,\"a\")\n",
    "\n",
    "    mongo = pymongo.MongoClient()\n",
    "    db = mongo[arquivo]\n",
    "\n",
    "    #print (\"Os arquivos:\"+salvarTweet+','+salvarApenasIdsTweets+','+salvarApenasTextoTweets+','+salvarLogErros+\" foram criados\")\n",
    "\n",
    "    try:\n",
    "        intervaloColeta = input(\"Qual o intervalo de coleta (em segundos)? (default 1500s)\") #3600\n",
    "        qtdeTweetsPorRequisicao = input(\"Qual a quantidade de tweets deseja por requisicao (min = 1 e max = 200)?\") #30\n",
    "    except:\n",
    "        intervaloColeta = 3600\n",
    "        qtdeTweetsPorRequisicao = 30\n",
    "\n",
    "    resp = raw_input(\"Deseja coletar da timeline do usuário dono das credenciais fornecidas? (S-sim, n-nao)\")\n",
    "\n",
    "    if (resp != 'n'):\n",
    "        screen_name = getScreenNameAuthUser()\n",
    "        collection = db[screen_name]\n",
    "        collection2 = db[screen_name+\"_completeJSON\"]\n",
    "        #collection.find_one()\n",
    "        #screen_name is the name of the logged user\n",
    "        #pegarTimelineAuthUserProjetoTimeline(tweets_texto, destino, tweets_ids, collection, screen_name, intervaloColeta, qtdeTweetsPorRequisicao)\n",
    "        pegarTimelineAuthUserProjetoTimeline(collection, collection2, screen_name, intervaloColeta, qtdeTweetsPorRequisicao)\n",
    "    else: \n",
    "        userName = raw_input(\"Qual nome do usuario que voce deseja coletar dados da timeline (sem '@') ?\")\n",
    "        userName = userName.replace(\"@\",\"\")\n",
    "        collection = db[userName]\n",
    "        collection2 = db[userName+\"_completeJSON\"]\n",
    "        #pegarTweetsDeUmUsuarioQtdeIntervalo(userName, tweets_texto,destino,tweets_ids, collection, intervaloColeta,qtdeTweetsPorRequisicao)\n",
    "        pegarTweetsDeUmUsuarioQtdeIntervalo(userName, collection, collection2, intervaloColeta,qtdeTweetsPorRequisicao)\n",
    "\n",
    "    print(\"A coleta esta sendo realizada. Sente, tome um cafe e trabalhe em outra coisa. Ou coloque outra coleta pra rodar, caso deseje. =D\")\n",
    "    #coletarTweetsAntigos(arq, destino,log)#coleta por ids que estao no arquivo idsTweets\n",
    "\n",
    "\n",
    "    destino.close()\n",
    "    tweets_texto.close()\n",
    "    log.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executando localmente\n",
    "\n",
    "Para executar o programa digite no seu terminal: python pegarTweetsProjTimeline.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando o dataset\n",
    "\n",
    "A partir deste ponto você pode seguir como quiser, fica aqui apenas uma sugestão de como carregar o dataset.\n",
    "\n",
    "Se você é minimamente familiar com a linguagem R, abra o Rstudio e digite no terminal dele os comandos abaixo.\n",
    "\n",
    "> install.packages(\"jsonlite\")\n",
    "\n",
    "> library(jsonlite)\n",
    "\n",
    "> nome_do_arquivo <- '/SeuLocalAqui/seuArquivo.json'\n",
    "\n",
    "> dataset <-jsonlite::stream_in(textConnection(readLines(nome_do_arquivo, n=1000)),verbose=F)\n",
    "\n",
    "Onde na última linha(dataset) o argumento \"n=1000\" do método readLines() se refere ao número máximo de linhas que você deseja visualizar, o que pode ser útil caso o dataset seja muito pesado e você não pretenda carregar tudo de uma vez."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
